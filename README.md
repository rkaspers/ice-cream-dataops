# CDF Bootcamp - Ice Cream Factory DataOps Solution

This repository contains the complete solution for the **Cognite Data Fusion (CDF) Bootcamp**, implementing a full DataOps pipeline for the Ice Cream Factory use case.


## ğŸ“‹ Overview

This project demonstrates a production-ready DataOps implementation using the **Cognite Toolkit** to manage and deploy resources to Cognite Data Fusion. The solution ingests data from the Ice Cream Factory API, transforms it, and calculates OEE (Overall Equipment Effectiveness) metrics.

## ğŸ—ï¸ Architecture

The solution implements a complete data pipeline with the following components:

### Data Flow
```
Ice Cream Factory API
    â†“
Hosted Extractors (Assets & Time Series)
    â†“
RAW Tables
    â†“
Transformations (Asset Hierarchy & Contextualization)
    â†“
Data Model Instances
    â†“
Functions (Datapoints Extraction & OEE Calculation)
    â†“
Analytics & Insights
```

### Workflow Pipeline

The automated workflow (`wf_icapi_data_pipeline`) orchestrates the entire data pipeline:

1. **create_asset_hierarchy** - Transformation that creates asset hierarchy from RAW data
2. **contextualize_ts_assets** - Transformation that links time series to assets
3. **icapi_datapoints_extractor** - Function that extracts datapoints from the API
4. **oee_timeseries** - Function that calculates OEE metrics

## ğŸ“ Project Structure

```
workspace/
â”œâ”€â”€ cdf.toml                          # Cognite Toolkit configuration
â”œâ”€â”€ ice-cream-dataops/                # Main organization directory
â”‚   â”œâ”€â”€ config.test.yaml              # Test environment configuration
â”‚   â”œâ”€â”€ config.prod.yaml              # Production environment configuration
â”‚   â””â”€â”€ modules/
â”‚       â””â”€â”€ bootcamp/
â”‚           â”œâ”€â”€ data_foundation/      # Base IAM and permissions
â”‚           â”‚   â””â”€â”€ auth/
â”‚           â”‚       â””â”€â”€ data_developer.Group.yaml
â”‚           â”œâ”€â”€ ice_cream_api/        # Ice Cream Factory integration
â”‚           â”‚   â”œâ”€â”€ auth/
â”‚           â”‚   â”‚   â””â”€â”€ icapi_extractors.Group.yaml
â”‚           â”‚   â”œâ”€â”€ data_models/
â”‚           â”‚   â”‚   â””â”€â”€ ice_cream_data_model.space.yaml
â”‚           â”‚   â”œâ”€â”€ data_sets/
â”‚           â”‚   â”‚   â””â”€â”€ data_sets.DataSet.yaml
â”‚           â”‚   â”œâ”€â”€ functions/
â”‚           â”‚   â”‚   â””â”€â”€ icapi_datapoints_extractor/
â”‚           â”‚   â”‚       â”œâ”€â”€ handler.py
â”‚           â”‚   â”‚       â”œâ”€â”€ ice_cream_factory_api.py
â”‚           â”‚   â”‚       â””â”€â”€ requirements.txt
â”‚           â”‚   â”œâ”€â”€ hosted_extractors/
â”‚           â”‚   â”‚   â””â”€â”€ Ice Cream Factory API/
â”‚           â”‚   â”‚       â”œâ”€â”€ assets/
â”‚           â”‚   â”‚       â”œâ”€â”€ timeseries/
â”‚           â”‚   â”‚       â””â”€â”€ Source.yaml
â”‚           â”‚   â”œâ”€â”€ raw/
â”‚           â”‚   â”‚   â””â”€â”€ ice-cream-factory-db.Table.yaml
â”‚           â”‚   â”œâ”€â”€ transformations/
â”‚           â”‚   â”‚   â”œâ”€â”€ create_asset_hierarchy.Transformation.yaml
â”‚           â”‚   â”‚   â”œâ”€â”€ create_asset_hierarchy.Transformation.sql
â”‚           â”‚   â”‚   â””â”€â”€ create_asset_hierarchy.schedule.yaml
â”‚           â”‚   â”œâ”€â”€ workflows/
â”‚           â”‚   â”‚   â”œâ”€â”€ wf_icapi_data_pipeline.Workflow.yaml
â”‚           â”‚   â”‚   â”œâ”€â”€ wf_icapi_data_pipeline.WorkflowVersion.yaml
â”‚           â”‚   â”‚   â””â”€â”€ wf_icapi_data_pipeline.WorkflowTrigger.yaml
â”‚           â”‚   â””â”€â”€ module.toml
â”‚           â””â”€â”€ use_cases/
â”‚               â””â”€â”€ oee/              # OEE calculation use case
â”‚                   â”œâ”€â”€ auth/
â”‚                   â”‚   â””â”€â”€ data_pipeline_oee.Group.yaml
â”‚                   â”œâ”€â”€ data_models/
â”‚                   â”‚   â””â”€â”€ oee_timeseries.space.yaml
â”‚                   â”œâ”€â”€ data_sets/
â”‚                   â”‚   â””â”€â”€ data_sets.DataSet.yaml
â”‚                   â”œâ”€â”€ functions/
â”‚                   â”‚   â””â”€â”€ oee_timeseries/
â”‚                   â”‚       â”œâ”€â”€ handler.py
â”‚                   â”‚       â””â”€â”€ requirements.txt
â”‚                   â””â”€â”€ module.toml
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ deploy.yaml               # GitHub Actions CI/CD pipeline
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9 or higher
- Access to a CDF project (e.g., `cdf-bootcamp-73-test`)
- Azure AD application with appropriate permissions
- Cognite Toolkit CLI installed (`pip install cognite-toolkit`)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd bootcamp/workspace
   ```

2. **Install dependencies**
   ```bash
   pip install cognite-toolkit
   ```

3. **Set up environment variables**

   Create a `.env` file in the `ice-cream-dataops/` directory:
   ```bash
   # CDF Project Configuration
   CDF_PROJECT=cdf-bootcamp-73-test
   CDF_CLUSTER=westeurope-1
   
   # Azure AD Configuration
   IDP_TENANT_ID=<your-tenant-id>
   IDP_CLIENT_ID=<your-client-id>
   IDP_CLIENT_SECRET=<your-client-secret>
   IDP_TOKEN_URL=https://login.microsoftonline.com/<tenant-id>/oauth2/v2.0/token
   IDP_SCOPES=https://<cluster>.cognitedata.com/.default
   
   # Extractor Credentials
   ICAPI_EXTRACTORS_CLIENT_ID=<extractor-client-id>
   ICAPI_EXTRACTORS_CLIENT_SECRET=<extractor-client-secret>
   
   # OEE Pipeline Credentials
   DATA_PIPELINE_OEE_CLIENT_ID=<oee-client-id>
   DATA_PIPELINE_OEE_CLIENT_SECRET=<oee-client-secret>
   ```

### Deployment

1. **Build the configuration**
   ```bash
   cd workspace
   cdf build
   ```

2. **Deploy to CDF (dry-run)**
   ```bash
   cdf deploy --dry-run
   ```

3. **Deploy to CDF**
   ```bash
   cdf deploy
   ```

## ğŸ”§ Key Components

### Hosted Extractors

Two hosted extractors pull data from the Ice Cream Factory API:

- **Assets Extractor**: Fetches asset data daily and stores it in RAW
- **Time Series Extractor**: Fetches time series metadata hourly

### Transformations

- **create_asset_hierarchy**: Creates a structured asset hierarchy in CDF from RAW data
  - Scheduled to run daily at 01:13 AM
  - Transforms flat RAW data into hierarchical asset structure

- **contextualize_ts_assets**: Links time series to their corresponding assets
  - Uses matching logic to associate data streams with equipment

### Functions

- **icapi_datapoints_extractor**: Extracts historical datapoints from the API
  - Configurable time window (default: 1 hour)
  - Writes data to CDF time series

- **oee_timeseries**: Calculates OEE metrics
  - Availability, Performance, Quality, and Overall OEE
  - Processes data from multiple production lines

### Workflows

The `wf_icapi_data_pipeline` workflow orchestrates the entire pipeline:
- Ensures proper execution order with dependencies
- Includes retry logic (3 retries per task)
- Aborts on failure to maintain data consistency
- Can be triggered manually or on a schedule

## ğŸ” Security & Permissions

The solution implements least-privilege access control with three IAM groups:

1. **data_developer**: Full administrative access for development
2. **icapi_extractors**: Permissions for ingesting and transforming data
3. **data_pipeline_oee**: Permissions for OEE calculations

Each group has precisely scoped capabilities to specific datasets and spaces.

## ğŸ“Š Data Models

- **Ice Cream Factory Data Model** (`icapi_dm_space`): Contains assets and time series
- **OEE Time Series** (`oee_ts_space`): Contains calculated OEE metrics

## ğŸ”„ CI/CD Pipeline

The repository includes GitHub Actions workflow for automated deployment:
- Validates configuration on pull requests
- Automatically deploys to test/prod environments on merge
- Located in `.github/workflows/deploy.yaml`

## ğŸ“š Learning Outcomes

This bootcamp solution demonstrates:

- âœ… Infrastructure as Code (IaC) with Cognite Toolkit
- âœ… Data ingestion using Hosted Extractors
- âœ… Data transformation with CDF Transformations
- âœ… Serverless computing with CDF Functions
- âœ… Workflow orchestration
- âœ… IAM and security best practices
- âœ… CI/CD automation with GitHub Actions
- âœ… Data model design and implementation

## ğŸ› ï¸ Troubleshooting

### Check Group Permissions

A utility script is provided to verify IAM group permissions:

```bash
cd ice-cream-dataops
python3 check_group_permissions.py
```

This will display all capabilities for the `icapi_extractors` group and verify required permissions.

### Common Issues

1. **403 Forbidden errors**: Check that IAM groups have proper permissions
2. **Transformation failures**: Verify RAW data exists and is properly formatted
3. **Function timeouts**: Adjust timeout values in workflow definition
4. **Hosted extractor errors**: Verify API connectivity and credentials

## ğŸ“– Resources

- [Cognite Toolkit Documentation](https://developer.cognite.com/sdks/toolkit/)
- [CDF Bootcamp Materials](https://docs.cdf-bootcamp.cogniteapp.com/)
- [Cognite Python SDK](https://cognite-sdk-python.readthedocs-hosted.com/)

## ğŸ‘¥ Contributing

This is a bootcamp solution repository. For improvements or questions:
1. Create an issue describing the problem or enhancement
2. Submit a pull request with proposed changes
3. Ensure all tests pass and configuration validates

## ğŸ“ License

This project is part of the Cognite Data Fusion Bootcamp training materials.

---

**Project**: cdf-bootcamp-73-test  
**Environment**: Test/Production  
**Toolkit Version**: 0.6.19

